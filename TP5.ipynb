{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Areal Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"logo.jpg\" width=150 ALIGN=\"left\" border=\"20\">\n",
    "<h1> Starting Kit for raw data (images)</h1>\n",
    "<br>This code was tested with <br>\n",
    "Python 3.6.7 <br>\n",
    "Created by Areal Team <br><br>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, \n",
    "INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Introduction </h2>\n",
    "     <br>\n",
    "Aerial imagery has been a primary source of geographic data for quite a long time. With technology progress, aerial imagery became really practical for remote sensing : the science of obtaining information about an object, area or phenomenon.\n",
    "Nowadays, there are many uses of image recognition spanning from robotics/drone vision to autonomous driving vehicules or face detection.\n",
    "<br>\n",
    "In this challenge, we will use pre-processed data, coming from landscape images. The goal is to learn to differentiate common and uncommon landscapes such as a beach, a lake or a meadow.\n",
    "    Data comes from part of the data set (NWPU-RESISC45) originally used in <a href=\"https://arxiv.org/pdf/1703.00121.pdf?fbclid=IwAR16qo-EX_Z05ZpxvWG8F-oBU0SlnY-3BPCWBVVOGPyJcVy7BBqCKjnsvJo\">Remote Sensing Image Scene Classification</a>. This data set contains 45 categories while we only kept 13 out of them.\n",
    "\n",
    "References and credits: \n",
    "Yuliya Tarabalka, Guillaume Charpiat, Nicolas Girard for the data sets presentation.<br>\n",
    "Gong Cheng, Junwei Han, and Xiaoqiang Lu, for the original article on the chosen data set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements \n",
    "\n",
    "The next cell will install all the required dependencies on your computer. You should consider replacing pip with pip3 if pip is related to python2.7 on your computer, or comment it if you already have the dependencies/are running in the docker of the challenge (runnable with the name areal/codalab:pytorch if you know how to run a docker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"sample_code_submission\"\n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through the challenge website and watch the trailer video.\n",
    "\n",
    "#### Question 1: Briefly explain the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: What is the scoring metric used to evaluate submissions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1> Step 1: Exploratory data analysis </h1>\n",
    "<p>\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = 'sample_data'\n",
    "data_dir = 'sample_data' # download \"public_data\" from the challenge website\n",
    "data_name = 'Areal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red \" >Warning</h2>\n",
    "\n",
    "<p style=\"font-style:italic\"> In case you want to load the full data </p> \n",
    "Files being big, your computer needs to have enough space available in your RAM. It should take about 3-4GB while loading and 1.5GB in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sample_data/Areal_train from AutoML format\n",
      "Number of examples = 65\n",
      "Number of features = 49152\n",
      "        Class\n",
      "0       beach\n",
      "1   chaparral\n",
      "2       cloud\n",
      "3      desert\n",
      "4      forest\n",
      "5      island\n",
      "6        lake\n",
      "7      meadow\n",
      "8    mountain\n",
      "9       river\n",
      "10        sea\n",
      "11   snowberg\n",
      "12    wetland\n",
      "Number of classes = 13\n"
     ]
    }
   ],
   "source": [
    "from ingestion_program.data_io import read_as_df\n",
    "data = read_as_df(data_dir  + '/' + data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 49153)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_1_1_R</th>\n",
       "      <th>pixel_1_1_G</th>\n",
       "      <th>pixel_1_1_B</th>\n",
       "      <th>pixel_1_2_R</th>\n",
       "      <th>pixel_1_2_G</th>\n",
       "      <th>pixel_1_2_B</th>\n",
       "      <th>pixel_1_3_R</th>\n",
       "      <th>pixel_1_3_G</th>\n",
       "      <th>pixel_1_3_B</th>\n",
       "      <th>pixel_1_4_R</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_128_126_R</th>\n",
       "      <th>pixel_128_126_G</th>\n",
       "      <th>pixel_128_126_B</th>\n",
       "      <th>pixel_128_127_R</th>\n",
       "      <th>pixel_128_127_G</th>\n",
       "      <th>pixel_128_127_B</th>\n",
       "      <th>pixel_128_128_R</th>\n",
       "      <th>pixel_128_128_G</th>\n",
       "      <th>pixel_128_128_B</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>121</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>53</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>191</td>\n",
       "      <td>164</td>\n",
       "      <td>134</td>\n",
       "      <td>196</td>\n",
       "      <td>169</td>\n",
       "      <td>139</td>\n",
       "      <td>202</td>\n",
       "      <td>175</td>\n",
       "      <td>145</td>\n",
       "      <td>desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193</td>\n",
       "      <td>168</td>\n",
       "      <td>138</td>\n",
       "      <td>191</td>\n",
       "      <td>166</td>\n",
       "      <td>136</td>\n",
       "      <td>201</td>\n",
       "      <td>176</td>\n",
       "      <td>146</td>\n",
       "      <td>194</td>\n",
       "      <td>...</td>\n",
       "      <td>196</td>\n",
       "      <td>171</td>\n",
       "      <td>140</td>\n",
       "      <td>197</td>\n",
       "      <td>172</td>\n",
       "      <td>141</td>\n",
       "      <td>201</td>\n",
       "      <td>176</td>\n",
       "      <td>145</td>\n",
       "      <td>desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>110</td>\n",
       "      <td>91</td>\n",
       "      <td>115</td>\n",
       "      <td>107</td>\n",
       "      <td>88</td>\n",
       "      <td>141</td>\n",
       "      <td>133</td>\n",
       "      <td>114</td>\n",
       "      <td>meadow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>15</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>river</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>80</td>\n",
       "      <td>99</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>182</td>\n",
       "      <td>197</td>\n",
       "      <td>202</td>\n",
       "      <td>121</td>\n",
       "      <td>135</td>\n",
       "      <td>144</td>\n",
       "      <td>120</td>\n",
       "      <td>137</td>\n",
       "      <td>147</td>\n",
       "      <td>mountain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_1_1_R  pixel_1_1_G  pixel_1_1_B  pixel_1_2_R  pixel_1_2_G  \\\n",
       "0          145          145          121          113          113   \n",
       "1          193          168          138          191          166   \n",
       "2           83           86           67           65           68   \n",
       "3           16           52           48           15           51   \n",
       "4           60           79           47           80           99   \n",
       "\n",
       "   pixel_1_2_B  pixel_1_3_R  pixel_1_3_G  pixel_1_3_B  pixel_1_4_R  ...  \\\n",
       "0           89           73           75           53           65  ...   \n",
       "1          136          201          176          146          194  ...   \n",
       "2           49           73           78           58           78  ...   \n",
       "3           47           15           52           45           15  ...   \n",
       "4           67           62           81           51           45  ...   \n",
       "\n",
       "   pixel_128_126_R  pixel_128_126_G  pixel_128_126_B  pixel_128_127_R  \\\n",
       "0              191              164              134              196   \n",
       "1              196              171              140              197   \n",
       "2              115              110               91              115   \n",
       "3               65               83               61               58   \n",
       "4              182              197              202              121   \n",
       "\n",
       "   pixel_128_127_G  pixel_128_127_B  pixel_128_128_R  pixel_128_128_G  \\\n",
       "0              169              139              202              175   \n",
       "1              172              141              201              176   \n",
       "2              107               88              141              133   \n",
       "3               75               56               68               85   \n",
       "4              135              144              120              137   \n",
       "\n",
       "   pixel_128_128_B    target  \n",
       "0              145    desert  \n",
       "1              145    desert  \n",
       "2              114    meadow  \n",
       "3               66     river  \n",
       "4              147  mountain  \n",
       "\n",
       "[5 rows x 49153 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "num_toshow = 6\n",
    "fig, _axs = plt.subplots(nrows=2, ncols=3, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "axs = _axs.flatten()\n",
    "\n",
    "for i in range(num_toshow):\n",
    "    img = data.iloc[i].values[:-1].reshape(128,128,3)\n",
    "    label = data.iloc[i].values[-1:]\n",
    "    axs[i].set_title('Example of {}'.format(label))\n",
    "    axs[i].imshow(img.astype(float) / 255)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iloc[:, -1:])\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data[\"target\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"target\"]==\"island\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code 1: compute statistics of the dataset.\n",
    "\n",
    "* How many features?\n",
    "* How many data points?\n",
    "* How many classes?\n",
    "* What is the most represented class?\n",
    "* What is the least represented class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features: 128*128*3\n",
    "#Data points: 5200\n",
    "#Classes: 13\n",
    "#They are equally represented: all by 400 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 : Building a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:red \" >Warning</h2>\n",
    "\n",
    "<p style=\"font-style:italic\"> In case you want to load the full data </p> \n",
    "This time, also, still make sure that your RAM has at least 2-3GB available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(data_name, data_dir, replace_missing=False, verbose=True)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing\n",
    "\n",
    "Basically, there are two approaches:\n",
    "\n",
    "* Use raw data as input. This may be the good way to go with, for instance, deep learning models.\n",
    "* Do feature engineering: process the data to create features. You can then use this features as the input of your classifier (Random forest, SVM, etc.). An example of feature is the number of blue pixel in the image. Feature extraction can also be done by a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (if you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of the baseline model\n",
    "\n",
    "Using our BasicCNN model needs PyTorch libraries installed.\n",
    "\n",
    "In case you have them but still encounter errors related to them, you should probably do an upgrade : \n",
    "\n",
    "    pip install -U torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is a simple implementation of a Convolutional Neural Network (CNN).\n",
    "\n",
    "More information on CNN:\n",
    "* [Convolutional neural network on Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n",
    "* [A Comprehensive Guide to Convolutional Neural Networks (blog)](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_code_submission.model import BasicCNN, SimpleConvModel\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SimpleConvModel()\n",
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = BasicCNN(verbose=True, use_cuda=True)\n",
    "print(m.model_conv)\n",
    "trained_model_name = model_dir + data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = m.predict(D.data['X_train'])\n",
    "Y_hat_valid = m.predict(D.data['X_valid'])\n",
    "Y_hat_test = m.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_result_submission/Areal_test.predict\r\n",
      "sample_result_submission/Areal_train.predict\r\n",
      "sample_result_submission/Areal_valid.predict\r\n"
     ]
    }
   ],
   "source": [
    "# m.save(trained_model_name)                 \n",
    "result_name = result_dir + data_name\n",
    "from data_io import write\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: What are the hyperparameters of a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code 2: Edit model.py to vary the CNN's hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO in model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code 3: Try another model (e.g. Random Forest, SVM, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO in another model.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring the result\n",
    "\n",
    "Obviously, since it is made with sample_data, which has too few samples, results won't be really good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring metric: accuracy\n"
     ]
    }
   ],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal score for the accuracy metric = 1.0000\n",
      "Training score for the accuracy metric = 0.4515\n"
     ]
    }
   ],
   "source": [
    "print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train))\n",
    "print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "if len(D.data['Y_valid']) > 0 and len(D.data['Y_test']) > 0:\n",
    "    print('Valid score for the', metric_name, 'metric = %5.4f' % scoring_function(D.data['Y_valid'], Y_hat_valid))\n",
    "    print('Test score for the', metric_name, 'metric = %5.4f' % scoring_function(D.data['Y_test'], Y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  74,   0,  20,  63,  72,  17,   7,   0,   0, 100,  47,   0],\n",
       "       [  0, 378,   0,  19,   2,   0,   0,   0,   0,   0,   0,   1,   0],\n",
       "       [  0,  51,   0,   5,  22,  58,  25,   0,   0,   0, 152,  87,   0],\n",
       "       [  0,  36,   0, 351,   0,   0,   0,   7,   0,   0,   5,   1,   0],\n",
       "       [  0,  75,   0,   6, 269,   0,  13,  37,   0,   0,   0,   0,   0],\n",
       "       [  0,   6,   0,   1,  12, 318,  20,  12,   0,   0,  23,   8,   0],\n",
       "       [  0,  64,   0,   2,  68,  12, 216,  20,   0,   0,  13,   5,   0],\n",
       "       [  0,   9,   0,   2,  11,   0,   0, 378,   0,   0,   0,   0,   0],\n",
       "       [  0, 190,   0,  33,  89,   2,  32,  36,   0,   0,  12,   6,   0],\n",
       "       [  0,  48,   0,   3, 188,  10,  69,  36,   0,   0,  43,   3,   0],\n",
       "       [  0,   0,   0,   0,   7,  33,   9,   0,   0,   0, 339,  12,   0],\n",
       "       [  0,  42,   0,   0,  30,   5,   6,   0,   0,   0, 218,  99,   0],\n",
       "       [  0, 144,   0,   2, 141,   2,  34,  62,   0,   0,  14,   1,   0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_train, Y_hat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: what does the confusion matrix represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code 4: display the confusion matrix with a colored heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV scores on sample_data doesn't have enough data, and so isn't meaningful.\n",
    "Run it with the full data to see meaningful values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV score (95 perc. CI): 0.12 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(BasicCNN(), X_train, Y_train, cv=3, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5: Why is there a standard deviation associated with the cross-validation score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Example needs to have python3 installed\n",
    "\n",
    "Test to see whether submission with ingestion program is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input_dir: /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data\n",
      "Using output_dir: /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/starting_kit/sample_result_submission\n",
      "Using program_dir: /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/starting_kit/ingestion_program\n",
      "Using submission_dir: /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/starting_kit/sample_code_submission\n",
      "\n",
      "========== Ingestion program version 6 ==========\n",
      "\n",
      "************************************************\n",
      "******** Processing dataset Areal ********\n",
      "************************************************\n",
      "========= Reading and converting data ==========\n",
      "Info file found : /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_public.info\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_feat.type\n",
      "[+] Success in  0.02 sec\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_train.data\n",
      "[+] Success in 49.47 sec\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_train.solution\n",
      "[+] Success in  0.13 sec\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_valid.data\n",
      "[+] Success in 18.58 sec\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_valid.solution\n",
      "[+] Success in  0.00 sec\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_test.data\n",
      "[+] Success in 19.27 sec\n",
      "========= Reading /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/public_data/Areal_test.solution\n",
      "[+] Success in  0.00 sec\n",
      "DataManager : Areal\n",
      "info:\n",
      "\tusage = Sample dataset Areal data\n",
      "\tname = areal\n",
      "\ttask = multiclass.classification\n",
      "\ttarget_type = Categorical\n",
      "\tfeat_type = Numerical\n",
      "\tmetric = accuracy\n",
      "\ttime_budget = 12000\n",
      "\tfeat_num = 49152\n",
      "\ttarget_num = 13\n",
      "\tlabel_num = 13\n",
      "\ttrain_num = 5200\n",
      "\tvalid_num = 1950\n",
      "\ttest_num = 1950\n",
      "\thas_categorical = 0\n",
      "\thas_missing = 0\n",
      "\tis_sparse = 0\n",
      "\tformat = dense\n",
      "data:\n",
      "\tX_train = array(5200, 49152)\n",
      "\tY_train = array(5200, 1)\n",
      "\tX_valid = array(1950, 49152)\n",
      "\tY_valid = array(0,)\n",
      "\tX_test = array(1950, 49152)\n",
      "\tY_test = array(0,)\n",
      "feat_type:\tarray(0,)\n",
      "feat_idx:\tarray(49152,)\n",
      "\n",
      "[+] Size of uploaded data  48.00 bytes\n",
      "[+] Cumulated time budget (all tasks so far)  12000.00 sec\n",
      "[+] Time budget for this task 12000.00 sec\n",
      "[+] Remaining time after reading data 11909.06 sec\n",
      "======== Creating model ==========\n",
      "**********************************************************\n",
      "****** Attempting to reload model to avoid training ******\n",
      "**********************************************************\n",
      "Model reloaded from: /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/starting_kit/sample_code_submission/Areal_model.pickle\n",
      "[+] Model reloaded, no need to train!\n",
      "[+] Prediction success, time spent so far 120.26 sec\n",
      "======== Saving results to: /home/adrien/Documents/competitions/Image_recognition_challenge/image_recognition/starting_kit/sample_result_submission\n",
      "[+] Results saved, time spent so far 121.45 sec\n",
      "[+] End cycle, time left 11878.55 sec\n",
      "[+] Done\n",
      "[+] Overall time spent 157.82 sec ::  Overall time budget 12000.00 sec\n"
     ]
    }
   ],
   "source": [
    "!python3 $problem_dir/ingestion.py $data_dir $result_dir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scoring program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Set 1 (Areal_train): accuracy(set1_score)=0.256153846154 =======\r\n"
     ]
    }
   ],
   "source": [
    "scoring_output_dir = 'scoring_output'\n",
    "!python3 $score_dir/score.py $data_dir $result_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit one of these files:\n",
      "./sample_code_submission_20-12-02-15-35.zip\n",
      "./sample_result_submission_20-12-02-15-35.zip\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = './sample_code_submission_' + the_date + '.zip'\n",
    "sample_result_submission = './sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to submit your submissions on Codalab!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
